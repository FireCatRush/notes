
- 1. 通过适当复制元素来扩展一个或两个数组，以便在转换之后，两个张量具有相同的形状；
- 2. 对生成的数组执行按元素操作。
在 PyTorch 中，**广播机制（Broadcasting Mechanism）** 使张量（Tensor）在形状不同的情况下也能进行运算，而无需显式地进行维度扩展。这种机制可以避免不必要的内存开销，并使代码更加简洁高效。当两个形状不同的张量进行按元素运算（如加法、减法、乘法等）时，PyTorch 会尝试**自动扩展**较小的张量，使其与较大的张量在维度上匹配。这种扩展是**虚拟的**，不会实际复制数据，仅在计算时进行逻辑扩展。
```python
import torch

a = torch.ones((3, 1))  # 形状为 (3, 1)
b = torch.ones((1, 4))  # 形状为 (1, 4)

result = a + b  # 广播机制生效
print(result.shape)
# torch.Size([3, 4])
```

在 PyTorch 中，广播机制遵循以下 **两条规则**：

1. **从后向前匹配维度**
    - 如果两个张量的维度数量不同，较少的维度将通过在前面补 `1` 来对齐。
2. **维度匹配规则**
    - 如果两个维度的大小相等，或者其中一个维度是 `1`，那么这两个维度是兼容的，可以进行广播。
    - 如果维度不相等且都不为 `1`，则无法进行广播。

## ✅ **合法的广播示例

| 张量 A 形状     | 张量 B 形状     | 结果形状        | 说明          |
| ----------- | ----------- | ----------- | ----------- |
| `(3, 1)`    | `(1, 4)`    | `(3, 4)`    | 维度可匹配，进行广播  |
| `(3, 1, 4)` | `(1, 4)`    | `(3, 1, 4)` | 自动补齐维度并广播   |
| `(5, 4, 1)` | `(1, 4, 3)` | `(5, 4, 3)` | 对应维度兼容，进行广播 |
## ❌ **非法的广播示例**

|张量 A 形状|张量 B 形状|错误原因|
|---|---|---|
|`(3, 2)`|`(3, 3)`|第二个维度不匹配|
|`(2, 3, 4)`|`(3, 4)`|第一个维度不匹配|

## 手动实现广播
```python
a = torch.tensor([1, 2, 3])  # (3,)
b = torch.tensor([4, 5])     # (2,)

# 手动调整形状
a = a.unsqueeze(1)  # (3, 1)
b = b.unsqueeze(0)  # (1, 2)

result = a + b
print(result.shape) # torch.Size([3, 2])
```

```python
a = torch.tensor([[1], [2], [3]])  # (3, 1)
b = a.expand(3, 4)  # 手动广播到 (3, 4)
print(b)
'''
tensor([[1, 1, 1, 1],
        [2, 2, 2, 2],
        [3, 3, 3, 3]])
'''
```

```python
a = torch.ones((3, 2))
b = torch.ones((2, 4))

result = a + b  # 会报错
# RuntimeError: The size of tensor a (2) must match the size of tensor b (4) at non-singleton dimension 1
